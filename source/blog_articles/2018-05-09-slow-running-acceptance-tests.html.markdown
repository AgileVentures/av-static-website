So that feels like quite a big breakthrough yesterday to get a complete green run of the acceptance tests by running them in the debugger.  I've kicked them off this morning to check, and I notice that I'm getting a few failures.  However I am running a big batch of other tests for the AV site, so perhaps the speed issues there are affecting things.  Or that we're just stuck with unreliable tests for the time being.  The difficulty with them being slow running is that it breaks up the progress that I can make on other tasks, and in particular with the spectron tests there always used to be a problem with the headed electron operation needing complete control of the computer to operate.  I'm not sure if that's still the case, but anyway, I've moved to my other laptop to blog about this while the tests are running.

So anyway, I kill the other background acceptance test process and kick off the private code app acceptance tests from vscode, and we shall see if we get any errors.  The problem with long running acceptance tests is that they burn up time as you wait to see if they are all passing.  That's not such a big deal if they'll run in the background, or in CI, but we're not there yet with this project.  Assuming that they do pass then I can maybe take another look at why the cucumberjs can't even get started on this project, and even if I can't fix it, then post a help request on github or something.  Okay, interesting, without the background load I get a complete green suite for the acceptance tests launched from the debugger.

So I merge in the PR I have to add the test runs from the debugger, the OSX fail notes and the timeout cleanup.  I then pull that into the projects branch, where I hope I can reliably test whether the changes we've made for the introduction of projects is affecting the existing acceptance tests or not ... I see we are getting a repeated fail on the save document step.  The error we're getting is pretty much consistenly mismatched meta-data.

I suspect this is down to new meta-data specific to the projects feature. So the simple fix is update that meta-data ... I get one of them passing, but it's date dependent, so either mock the date somewhere or slightly less reliably work out the current date and stick it in the test check.  I could also be looking into where this metadata is being set and updated ... I see there's a simple date manipulation operation there.  I copy it into the test and they pass; so then I feel inclined to pull that code out somewhere so the operation can be labelled and we can re-use the same operation without duplicating it, as well as stubbing it easily if we want to. 

I do that extract method refactoring and even end up creating a couple of unit tests for the new method.  The unit tests are not great.  Seems like I'd need to start stubbing Date to get them real precise and I don't want to go there.  In the first instance I just check that the function returns something other than `undefined` (which I screwed up by leaving off the return statement first time round) and get one saving acceptance test passing.  Now there's the other failures and there are some longer path names I have to take care of.  I feel like I'm moving deckchairs when I should be grappling with this bigger project feature.  I do learn more about the nodejs path package.  Perhaps I should be easier-going here.  My big picture is get a full green on the projects feature spike, so that I can then get set to detect other issues in the app as we go forward ...

I'm starting to speed my way through the other save document fails now as I have the path and date handling in place.  Maybe I can find the vscode debug shortcut ... f5.  That's handy.  However there's still one close document error that seems to be unrelated to this meta-data thing.  I was hoping the meta-data fixes would sort it, but not so.  Ah well ...
