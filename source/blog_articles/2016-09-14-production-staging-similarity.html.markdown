---
title: Production and Staging Similarity
date: 2016-09-14
tags: coffeesscript hubot chatbot node express sinatra production staging heroku redis node debugging javascript
author: Sam Joseph
---

So Michael and I finished up an important piece of work on the [AgileBot](https://github.com/AgileVentures/agile-bot) yesterday.  At least we completed something we had started working on a while ago, which was getting the AgileBot legacy code wrapped in tests, and refactoring the config out of the main script file.  It seems like a good heuristic to finish what you start, although of course there's always the danger of throwing good money after bad, or rather time; since time is of course, money.  It's definitely been an interesting process though, and it feels very good to get to this point where we can catch our breath.

As I've mentioned before, AgileBot is a chunk of CoffeeScript that takes incoming requests to send notifications about hangouts from WebSiteOne (our Rails monolith for AgileVentures) and pass them on to Slack and Gitter.  AgileBot's CoffeeScript runs in Hubot (which runs on Node) and is deployed on Heroku.  AgileBot was an experiment from a couple of years ago to see what could be achieved in CoffeeScript (a Ruby flavoured variant of JavaScript) and Hubot.  Hubot has a range of functions and is extendible to allow it to respond to users in chat rooms, which is certainly something I've been interested in in the past.  Chatbots tend to become annoying rather quickly though, and users will often fail to take them seriously, although we do read reports of some [chatbots fooling students into thinking they are human](https://www.washingtonpost.com/news/innovations/wp/2016/05/11/this-professor-stunned-his-students-when-he-revealed-the-secret-identity-of-his-teaching-assistant/) in some online classes.

I'd love to be deploying really effective chatbot tech, but we're a small community and I think we're in the stage where value is being derived from authentic connections between humans, rather than automating 1000's of responses.  We've totally NOT played with the range of functions that Hubot can support, and the AgileBot script is taking advantage of Hubot's ability to act like an API endpoint and be a waypoint between our Rails monolith and the 3rd party endpoints of Gitter and Slack.  We've been making little changes to the AgileBot script over the months, and the lack of tests was a little nerve-wracking.  After tweaking the Jasmine tests on HangoutConnection we thought, yeah, let's get some tests wrapped around AgileBot.

I've blogged about parts of that before, and my nagging concern is that we could have completely re-created this micro service as a gem in our Rails monolith, or as a separate Sinatra micro service, faster than we could get the tests working and fix the associated issues.  In the meantime, particularly valiant solo efforts from Michael have got us to the point where the code is wrapped in integration tests, the config is refactored, and yesterday we got the new AgileBot deployed in production.

The big hurdle that came up at the end was that when we deployed the new code to the staging server we saw a thrashing in the logs.  The logs were dumping what looked like the entire list of our slack instance users in JSON format, and that's so big we couldn't see the actual error message.  It was this issue that we really took apart yesterday.  It was a tricky issue and while speculating about whether we'd been hacked, or the upgrade had changed some node modules out from under us, we made some progress by managing to replicate the error locally.  This took us copying the entire staging server config locally and running the hubot locally just as it would run on the Heroku server.  This allowed us to see some error specifics:

```
node_redis: no callback to send error: OOM command not allowed when used memory > 'maxmemory'.
[Tue Sep 13 2016 14:50:21 GMT+0100 (BST)] ERROR Error: OOM command not allowed when used memory > 'maxmemory'.
  at ReplyParser.<anonymous> (/Users/tansaku/Documents/GitHub/AgileVentures/agile-bot/node_modules/hubot-scripts/node_modules/redis/index.js:279:27)
  at emitOne (events.js:77:13)
  at ReplyParser.emit (events.js:169:7)
  at ReplyParser.send_error (/Users/tansaku/Documents/GitHub/AgileVentures/agile-bot/node_modules/hubot-scripts/node_modules/redis/lib/parser/javascript.js:296:10)
  at ReplyParser.execute (/Users/tansaku/Documents/GitHub/AgileVentures/agile-bot/node_modules/hubot-scripts/node_modules/redis/lib/parser/javascript.js:181:22)
  at RedisClient.on_data (/Users/tansaku/Documents/GitHub/AgileVentures/agile-bot/node_modules/hubot-scripts/node_modules/redis/index.js:504:27)
  at Socket.<anonymous> (/Users/tansaku/Documents/GitHub/AgileVentures/agile-bot/node_modules/hubot-scripts/node_modules/redis/index.js:82:14)
  at emitOne (events.js:77:13)
  at Socket.emit (events.js:169:7)
  at readableAddChunk (_stream_readable.js:146:16)
  at Socket.Readable.push (_stream_readable.js:110:10)
  at TCP.onread (net.js:523:20)
```

So it seemed like we might be having a problem with Redis, the key-value cache that Hubot uses as a memory.  We'd copied over the Redis URL from the server config, so our local Hubot was also hitting the same Redis cache as the staging server.  We cycled through various loops of trying to clear out that Redis cache, but to no avail.  Our AgileBot script doesn't use Redis at all.  It's just part of booting up Hubot, which also has its own Slack connections and code.  That we're spending time debugging something that's not really related to our microservice logic is fuel for my thoughts that we would move faster building an express or Sinatra app, but maybe getting distracted by those thoughts are counter-productive ...

Anyhow we couldn't seem to empty the Redis cache.  Even with resets and flushes and shutting everything down it still seemed to be filling up. We also tried deploying the master branch of the production code to staging and got the same thrashing issue.  This was an important step - we'd isolated the problem as not being related to any of the new code changes we'd introduced.  That's such a crucial step when debugging.  All our speculations about how all sorts of updates might be influencing this thrashing issue could be thrown out, and we could focus on the problem being either the Redis cache, or some unknown upgrade of a node module.  It's fascinating to me that npm doesn't create a lock of the particular versions that get installed.  When we use bundle in the Ruby world we get a `Gemfile.lock` file, and if you check that into git then the versions of libraries that every developer is using can't change without being explicitly updated.  Unless I'm missing something npm seems much more permissive.  At least if you don't check in the node_modules directory itself then any time you do a fresh install (say on Heroku) then you're doing the equivalent of Ruby's `bundle update`.  Maybe the Heroku build pack for node mitigates that somehow, but it feels like the node/npm keeps you more on the bleeding edge of your libraries?  That's both exhilarating and frightening! :-)

The fix for our thrashing problem came when Michael noticed that we had different Redis plugins on the production and staging instances of AgileBot.  HerokuRedis on production and RedisToGo on staging.  We uninstalled RedisToGo and installed HerokuRedis on staging.  The bug was gone locally, and gone from staging too.   A great reminder of how you really really really want staging to be as much like production as possible.  We were now able to proceed with doing manual acceptance tests of staging to check that hits from WebSiteOne would cause AgileBot to ping our Slack instance (but in suitable test channels), and that wasn't working.  We spent some time trying to get live debugging working in the context of Hubot, which was partially successful.  Michael wrote a debug Hubot script, and we got node-inspector running, and finally got the chrome inspector hooked on the debugger, but there was a time out and we lost the connection.  I've seen that with Rails running on Puma - the web server timeouts killing the debugger.

We gave up on that - worked out how to post to the Hubot logs, and then saw that the problem was that our Slack token wasn't set correctly.  Fixing that our manual acceptance tests worked.  We deployed to production just in time for a live test running the "Kent Beck" scrum - everything worked fine, and over night I can see the PacificRim scrum notified fine, and the days pair notifications came through fine too.

In the Kent Beck scrum Michael and I took stock, comparing the hours spent on getting the bots' legacy code wrapped in tests and deployed.  Michael thinks we spent less time getting to this point than we would trying to rebuild.  He might be right, but I think there's a range of rebuilding options including just switching to JavaScript, moving to express, or moving to Sinatra, with each having different pros/cons and likely times to completion.  Undeniably we are much more familiar with the Node/Hubot/CoffeeScript tech stack now, and that information is valuable.  Having got this far it would be silly not to now make a few more refactoring to AgileBot to deliver some noticeable improvements to our users, and see how our regression suite helps us make those changes; that much is clear.

The itch I still want to scratch though is how fast I could make an express or Sinatra micro service to do the same thing.  Am I delusional that I think I could do the Express one in a couple of days and the Sinatra one in half a day?  I won't drag Michael on that whale hunt :-) I think that's just something I need to burn my own spare time on to help in my internal estimation process.  I also worry that my constant questioning of the architecture of the system is kind of draining for people.  I want to work on the things that will deliver the most value to our users, and in turn generate revenue for AgileVentures that makes the whole charity enterprise sustainable.  I have so many thoughts, so many possibilities, but it really isn't clear to me where to focus.  Would it be easier for everyone if I just pretended that I was certain that a particular approach was the best? :-) Maybe that debate is just something that I should be having internally without dumping it on other people through blogs, scrums and pairing sessions?

I just love that feeling when you can jump up a level and say, right, we don't need to build X, we can achieve our goal by building Y.  I love jumping those levels.  I guess many others like to stay focused on one level, at least for longer than I do.  If one thing is certain it is that I think too much :-) More doing, less thinking/debating perhaps? :-) Still, the whole reason I enjoy working with AV is thinking about the architectural/team/structural decisions and how they can make us more efficient and sustainable.  I'll save the other thoughts I have on that for another micro-services blog.  In the meantime I think we can reflect that pithy sayings and heuristics can often be contradictory, but the take home today is: make sure your production and staging environments are as similar as they can possibly be!



